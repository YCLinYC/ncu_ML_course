{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Old_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdldIKUlVyhT+bHg6HFBWd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YCLinYC/ncu_ML_course/blob/main/Old_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWLDOmNVHhKq"
      },
      "source": [
        "# NCU ML General Education Course\r\n",
        "Due date: 2021/1/4\r\n",
        "\r\n",
        "Team member: 陳佑宏, 嚴毅澤, 黃昱東, 林昱辰"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psvurypCGmuj"
      },
      "source": [
        "# All codes below was basically copied from https://keras.io/api/applications/\r\n",
        "# All I did was just some minor tweaking to load in the data locally\r\n",
        "# and do some fine tuning to get better result hopefully\r\n",
        "\r\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\r\n",
        "from tensorflow.keras.layers import Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Pu3p95zIPbH"
      },
      "source": [
        "# create the base pre-trained model\r\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False)\r\n",
        "\r\n",
        "# this could also be the output of a different Keras model or layer\r\n",
        "input_tensor = Input(shape=(224, 224, 3))\r\n",
        "\r\n",
        "model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)\r\n",
        "\r\n",
        "# add a global spatial average pooling layer\r\n",
        "x = base_model.output\r\n",
        "x = GlobalAveragePooling2D()(x)\r\n",
        "# let's add a fully-connected layer\r\n",
        "x = Dense(1024, activation='relu')(x)\r\n",
        "# and a logistic layer -- let's say we have 200 classes\r\n",
        "predictions = Dense(200, activation='softmax')(x)\r\n",
        "\r\n",
        "# this is the model we will train\r\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\r\n",
        "\r\n",
        "# first: train only the top layers (which were randomly initialized)\r\n",
        "# i.e. freeze all convolutional InceptionV3 layers\r\n",
        "for layer in base_model.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr7T-zjeHfD_"
      },
      "source": [
        "\r\n",
        "# compile the model (should be done *after* setting layers to non-trainable)\r\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\r\n",
        "\r\n",
        "# train the model on the new data for a few epochs\r\n",
        "model.fit(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkeTDbjVHbzb"
      },
      "source": [
        "# at this point, the top layers are well trained and we can start fine-tuning\r\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\r\n",
        "# and train the remaining top layers.\r\n",
        "\r\n",
        "# let's visualize layer names and layer indices to see how many layers\r\n",
        "# we should freeze:\r\n",
        "for i, layer in enumerate(base_model.layers):\r\n",
        "   print(i, layer.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNJHBUPuGzUW"
      },
      "source": [
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\r\n",
        "# the first 249 layers and unfreeze the rest:\r\n",
        "for layer in model.layers[:249]:\r\n",
        "   layer.trainable = False\r\n",
        "for layer in model.layers[249:]:\r\n",
        "   layer.trainable = True\r\n",
        "\r\n",
        "# we need to recompile the model for these modifications to take effect\r\n",
        "# we use SGD with a low learning rate\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\r\n",
        "\r\n",
        "# we train our model again (this time fine-tuning the top 2 inception blocks\r\n",
        "# alongside the top Dense layers\r\n",
        "model.fit(...)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzozK-tyG1O4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}